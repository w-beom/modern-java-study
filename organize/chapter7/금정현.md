java 7 전 컬렉션 병렬 처리 어려움
스트림을 이용하여 순차 스트림을 병렬 스트림으로
청크? chunk = 상당한 양, 컬렉션을 분할할 단위?

![image](https://user-images.githubusercontent.com/10288037/111314550-dae2fe80-86a4-11eb-8436-803775cfac25.png)


7.1 병렬 스트림 242

![image](https://user-images.githubusercontent.com/10288037/111314565-ddddef00-86a4-11eb-97e0-f30d52a46a55.png)

parallel 할때 안할때 차이
안했을때(일반 Stream)

![image](https://user-images.githubusercontent.com/10288037/111314579-e1717600-86a4-11eb-9357-e9efc4d2bae5.png)

했을때 (parellel)

![image](https://user-images.githubusercontent.com/10288037/111314590-e46c6680-86a4-11eb-97af-1b9647695084.png)


성능 비교해보기

![image](https://user-images.githubusercontent.com/10288037/111314620-eafade00-86a4-11eb-9301-2da42a179fd0.png)

병렬 처리가 성능때문에 쓰는줄 알았는데 아닌건가?

OKKY에다가 질문 올려봄
### 질문 내용
Java Stream 병렬(Parallel)은 성능을 위한것이 아닌가요? 
둘 다 로직은 100 * 100 * 100만큼 숫자를 합치는 로직입니다
각각 시간을 체크해봤는데 parallel를 사용한 것이 2배 넘게 소요되었습니다..
전 병렬 처리 목적이 데이터가 많으면 효율적으로 처리하기 위함으로 생각했었고 그 의미가 성능이 빨라진다는 의미일줄 알았는데 시간 비교 해보니 충격적이네요..
혹시 이것에 대해 아시는분 계실까요?  

답변 내용
### (WRITE_IN_GO) 님

정수 1억개 더하는게 쓰레드 만들고 동기화하는것보다 비쌀 수도 있죠.
유저랜드랑 커널영역 오고가는게 생각보다 비쌉니다.

### (캐티) 님
CPU에서 병렬처리를 하여야 하는 이유는 다름아닌 레이턴시 부분때문이빈다.
가령 php 서버랑 노드 서버의차이를 극단적으로 설명해드리면 다음과 같스빈다.
HTTP 외부서버에서 데이터를 가져왔을때 차이. 데이터는 최종적으로 결합하여 출력하고 keep-alive 없음 가정.
PHP 서버는 curl을 사용하여 받아오므로 이걸 써야하빈다.
10개 경로에서 데이터를 가져올때 PHP 에서는 하나씩 가져오빈다.
노드 서버는 비동기 요청을 하는데 10개 경로 동시에 가져오빈다.
여기서 레이턴시 차이가 생기는 원인은 동시에 웹페이지가 요청되면 서버는 데이터를 동시에 준비할꺼빈다. 반면에 하나씩 전달되면 서버는 쉬엄쉬엄 데이터를 전달할꺼빈다.
병렬처리를 하여야 하는 이유이빈다.
자바 기반에서 스트림에는 컬렉션을 다룰 수 있는 기반을 가진걸로 찾아지빈다. (저는 자바 안써영 ...) 스트림이란게 2개를 이어서 코덱처럼 쓰기도 하고 그냥 컬렉션 같은 메모리스트림으로 쓰기도 하빈다. 여기서 병렬화는 컬렉션의 분량을 몇개로 나눠서 가용가능한 프로세스 내에서 처리해주빈다.
위에 예시로 단순 합 집계를 실행 하였는데 단순 합에 경우에 CPU 캐시메모리 내에서 모든 합을 집계하면 딱히 차이가 안날것 같스빈다. 머 동영상 같은 캐시메모리보다 큰 데이터에 인코딩이라던가 이런게 필요하빈다.
구글에 나오는 블로그 자료보다 공식문서가 기능들을 더 잘 어필하고 있스빈다.
Parallelism (The Java™ Tutorials > Collections > Aggregate Operations) (oracle.com) 
공식문서인데 기능을 제대로 어필 못하면 자바 플랫폼으로 고려할때 망설이지 않겠는쩌여.
컬렉션 요소를 꺼내는 람다식도 제공하므로 가령 gif 포멧 이미지에 애니메이션 인코딩 같은 부분이 가능할것 같스빈다. 머 단순하게 생각해서 가능해보이지 이건 또 머 프레임별로 용량 최적화가 따로 들어가는거라 활용방안 까지만 생각하고 얘기를 마쳐야겠스빈다.

### (rezigrene) 님
그건 하시는일은 sum = sum + i 로 매우 간단한데.
덧셈 한번하겠다고 병렬처리하기위한 스레드에 나눠담는 작업(오버헤드)을 하느라 시간을 잡아먹어서 그렇습니다.
그정도의 작업은 단순 for문을 사용하면 더욱더 빨라지겠죠. (10배나 빨라지네요)
이득을 보려면 작업하나하나가 CPU를 꽤 많이 써야 이득을 볼수 있으며, 이경우
스트림으로 변환하는 비용의 비율이 상대적으로 줄어 단순반복문과의 차이가 많이 줄어들고,
병렬처리하려고 드는 비용이 더해져도 CPU수만큼 나눠서 얻는 이득이 크게 됩니다.

아래는 실제 실험결과 입니다.

500000500000

500000500000

500000500000

StopWatch 'sum = sum + i': running time = 136870900 ns

---------------------------------------------
ns         %     Task name
---------------------------------------------

004349300  003%  단순반복문

043648500  032%  스트림

088873100  065%  병렬스트림

50005100005050

50005100005050

50005100005050

StopWatch '작업하나하나가많은경우': running time = 148956400 ns

---------------------------------------------

ns         %     Task name

---------------------------------------------

062951900  042%  작업많은단순반복문

067374700  045%  작업많은스트림

018629800  013%  작업많은병렬스트림

``` java
package com.example.demo;

import org.junit.jupiter.api.Test;
import org.springframework.util.StopWatch;

import java.util.stream.Stream;

public class MyTest {

    @Test
    public void test() {
        long limit = 1_000_000L;
        StopWatch sw = new StopWatch("sum = sum + i");
        sw.start("단순반복문");
        System.out.println(simpleSum(limit));
        sw.stop();
        sw.start("스트림");
        System.out.println(streamSum(limit));
        sw.stop();
        sw.start("병렬스트림");
        System.out.println(parallelSum(limit));
        sw.stop();

        System.out.println(sw.prettyPrint());

        long groupCount = 100;
        StopWatch sw2 = new StopWatch("작업하나하나가많은경우");
        sw2.start("작업많은단순반복문");
        System.out.println(simpleSum2(groupCount, limit));
        sw2.stop();
        sw2.start("작업많은스트림");
        System.out.println(streamSum2(groupCount, limit));
        sw2.stop();
        sw2.start("작업많은병렬스트림");
        System.out.println(parallelSum2(groupCount, limit));
        sw2.stop();

        System.out.println(sw2.prettyPrint());

    }

    private long simpleSum(long n) {
        long sum = 0;
        for (long i = 1; i <= n; i++) {
            sum += i;
        }
        return sum;
    }
    private long streamSum(long n) {
        return Stream.iterate(1L, i -> i + 1)
                .limit(n)
                .reduce(0L, Long::sum);
    }
    private long parallelSum(long n) {
        return Stream.iterate(1L, i -> i + 1)
                .limit(n)
                .parallel()
                .reduce(0L, Long::sum);
    }

    private long simpleSum2(long groups, long n) {
        long sum = 0;
        for (long i = 1; i <= groups; i++) {
            sum += highCpuWorks(i, n);
        }
        return sum;
    }
    private long streamSum2(long groups, long n) {
        return Stream.iterate(1L, i -> i + 1)
                .limit(groups)
                .map(i -> highCpuWorks(i, n))
                .reduce(0L, Long::sum);
    }
    private long parallelSum2(long groups, long n) {
        return Stream.iterate(1L, i -> i + 1)
                .limit(groups)
                .map(i -> highCpuWorks(i, n))
                .parallel()
                .reduce(0L, Long::sum);
    }


    private long highCpuWorks(long start, long end) {
        long sum = 0;
        for (long i = start; i <= start + end; i++) {
            sum += i;
        }
        return sum;
    }
}
```
### (esrse) 님
위에 댓글들 중에 이상한 말도 있고, 맞는 말도 있습니다만, 제가 첨언할 게 있어서 댓글답니다.
parallel은 sequential 스트림에 비해서 오버헤드가 존재하며, 경우에 따라서 그 오버헤드가 너무 커서 병렬화가 독이될 때가 있습니다. 병렬화에 수반되는 오버헤드보다, 병렬화된 연산이 절약할 시간이 더 클 경우에만 성능상에 이득이 있습니다.

Stream.iterate 는 오버헤드가 큽니다. Stream.limit는 병렬화가 도움이 안 됩니다.

parallel 동작은 stream source를 균형있게 여러개의 병렬 스트림으로 분할하는 작업부터 시작합니다.
이때 전체 원소의 개수가 미리 명확히 알려져있다면 분할작업이 용이할 것입니다. 그러나 Stream.iterate 를 쓰면 원소 개수를 미리 알 수 없으며 Stream.iterate는 첫번째 인자로 주어진 seed에 두번째 인자로 주어진 UnaryOperator 를 반복적용해서 원소를 생성해냅니다. 따라서 Stream.iterate를 소스 스트림으로 활용을 하면, 이것을 병렬화 하기 위해서 일단 1024개의 배열을 생성하고 UnaryOpeartor를 1023번 호출하고, 1024개의 원소를 얻어내어 그 배열에 담습니다. 이것이 하나의 병렬 스트림이죠. 그다음에 또 병렬화하기 위해서 2048개의 배열을 생성하고 UnaryOperator를 2048번 호출하고 2048개의 원소를 얻어내어 그 배열에 담습니다. 이것이 또 하나의 병렬 스트림이죠. 그리고 병렬화가 더 필요하다고 판단되면 이번엔 3072개의 배열을 생성하고.. 같은 작업을 통해서 또다른 병렬 스트림을 만들어 냅니다.
그리고 각각을 병렬로 동작시킵니다.
이렇게 하면 일단 배열을 생성하는 비용, 쓸데없이 3000번 이상 UnaryOperator를 호출한 비용, 그리고 값을 배열에 복사하는 비용이 오버헤드로 쓰였습니다.
이후에 병렬로 수행하려는 작업이 이 오버헤드보다 더 많은 시간 절약을 가져다주지 않는다면, 병렬화된 버전이 더 느린 겁니다.

limit의 동작은 병렬화된 상황에서는 도움이 안 된다는 점에 대해 이야기 해보죠. 이때는 ordered 스트림에 국한해보겠습니다. sequential로 동작했을 경우에는 딱 limit 개수만큼 계산을 한 뒤에 개수가 차면 작업이 끝납니다. 하지만 병렬로 하면, 병렬화된 스트림에 대해서 계산을 각각 모두 수행하고, 그 결과를 하나로 모아서 순서대로 정렬한 뒤에 그 중에 limit 개수만큼을 짤라서 다음연산으로 줘야 됩니다. 즉 쓸데 없는 계산 비용이 너무 들어가죠.

이번에 병렬 스트림을 사용해보시면서 한가지 배우셔야될 점은 parallel 동작이 어떻게 되는지 명확히 알기 전에는 사용하시면 안 된다는 것입니다. 병렬화를 통해서 스트림 성능 개선을 하시고 싶으면, 일단 스트림의 중간연산, 종단연산 내부 코드를 읽어보셔야 합니다.


----------------
paralle의 스레드는 몇 개?
자기 PC에 맞게 설정된다고함

병렬 스트림 사용요령
	- 확신이 없으면 직접 측정
	- 자동 박싱/언방싱은 성능 저하를 시키니 IntStream 같은걸로 쓸것
	- limit, findFirst는 paralle에서 비효율적임
	- unordered 하면 효율적
	- 소량 데이터는 별로임
	- LinkedList를 분할 할라면 모든 요소를 탐색해야 해서 별로임, ArrayList는 굳


소스 | 분해성
-- | --
ArrayList | 훌륭함
LinkedList | 나쁨
IntStream.range | 훌륭함
Stream.iterate | 나쁨
HashSet | 좋음
TreeSet | 좋음


	

7.2 포크/조인 프레임워크 255
![image](https://user-images.githubusercontent.com/10288037/111315083-6197db80-86a5-11eb-8d72-4a5204b4ea11.png)


오 어렵다



7.3 Spliterator 인터페이스 262

7.4 마치며 271
